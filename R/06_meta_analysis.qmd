---
title: "metaanalysis"
format: html
editor_options: 
  chunk_output_type: console
---

```{r load-packages}
library(brms)      # CRAN v2.23.0
library(legendry)  # CRAN v0.2.4
library(metafor)   # CRAN v4.8-0
library(tidyverse) # CRAN v2.0.0
library(here)      # CRAN v1.0.2
library(patchwork) # CRAN v1.3.2
library(tidybayes) # CRAN v3.0.7
library(ggtext)    # CRAN v0.1.2

options(mc.cores = 4)
```

We start by loading the final data table we made in previous script

```{r load-data}
data_allscales <- read_csv(here("data", "final_dataset_meta_analyses.csv"))
```


```{r filter-data}
data <- data_allscales |>
  group_by(response_name, urban_area, year, team) |>
  filter(AICc_baseline == min(AICc_baseline)) |>
  # if two spatial scales have exactly the same AIC, we keep the lowest
  filter(urban_scale == min(urban_scale)) |> 
  mutate(
    yi = case_when(is.autocor.spatial ~ yi_spatial, TRUE ~ yi_baseline),
    vi = case_when(is.autocor.spatial ~ vi_spatial, TRUE ~ vi_baseline)
  )
```

see eg https://doi.org/10.1890/14-0362.1 for an example where they ypicked the largest ES across scales
"When studies measured effects of wetland amount and forest amount at multiple spatial scales, we calculated an effect size for each variable at each scale. We then selected the largest estimate across scales (...)"

```{r filter-data-alt}
## an alt_approach to choosing ES, we first select for each scale whether the spatial or non spatial model should be retained
## then we pick the model with the strongest ES
## Can't use AIC on a mix of spatial and non-spatial models since AIC in spaMM seem to behave a bit differently (see their doc)
data2 <- data_allscales |>
  group_by(response_name, urban_area, year, team) |>
  mutate(
    yi = case_when(is.autocor.spatial ~ yi_spatial, TRUE ~ yi_baseline),
    vi = case_when(is.autocor.spatial ~ vi_spatial, TRUE ~ vi_baseline)
  ) |>
  filter(abs(yi) == max(abs(yi))) |>
  # if two spatial scales have exactly the same yi, we keep the lowest
  filter(urban_scale == min(urban_scale))
```

```{r compare-ES-filters}
plot(data$yi, data2$yi)
# the two methods give about the same results in most cases
```

```{r plot-retained-scales}
plot_retained_scales <- data |>
  ungroup() |>
  mutate(
    response_name_full = case_when(
      response_name == "brightness" ~ "abdomen brightness",
      response_name == "log_abdomen" ~ "relative abdomen area",
      response_name == "spider_length" ~ "spider length",
      response_name == "radius" ~ "web radius",
      response_name == "mesh_size" ~ "mesh width",
    )
  ) |>
  mutate(response_name_full = fct_relevel(
    response_name_full,
    "spider length", "relative abdomen area",
    "mesh width", "web radius",
    "abdomen brightness"
  )) |>
  ggplot() +
  geom_bar(aes(response_name_full, fill = urban_scale, group = urban_scale), position = "fill") +
  labs(fill = "spatial scale of effect of urbanization (m)") +
  scale_fill_distiller(type = "seq", palette = "Purples") +
  scale_x_discrete("") +
  scale_y_continuous("proportion of effect sizes") +
  theme_bw() +
  theme(legend.position = "bottom")

plot_retained_scales
```

```{r save-retained-scales-plot, dev='cairo_pdf'}
ggsave(here("plots", "SUPPL_retained_scales.pdf"),
  plot = plot_retained_scales, width = 7, height = 4
)

ggsave(here("plots", "SUPPL_retained_scales.png"),
  plot = plot_retained_scales, width = 7, height = 4
)
```


# Bayesian metaanalysis

relevant paper to read design priors and to follow citations:
https://doi.org/10.1002/jrsm.1475

## models with no moderators

### Justifying the choice of prior scales

Based on Senior et al 2016 (https://doi.org/10.1002/ecy.1591), we'd expect typical heterogeneity % to be in the high range for ecological data. We can do a bit of prior predictive check, using the sampling variances for each effect size:

```{r within-study-variances}
vres_tab <- data |>
  filter(!is.na(yi)) |>
  group_by(response_name) |>
  summarise(k = length(yi), sum_wi = sum(1 / vi), sum_wi_squared = sum((1 / (vi))^2)) |>
  mutate(var_res = (k - 1) * sum_wi / (sum_wi^2 - sum_wi_squared))
# see https://www.metafor-project.org/doku.php/faq#how_are_i_2_and_h_2_computed_i
# or eq 6 in https://doi.org/10.1186/s13750-023-00301-6 among many others
vres_tab
```

This gets us the "typical" sampling variance


Assuming the SDs of the between study random effects have a half-Normal prior, we can check different values of the SD of that prior `priorSD`, and see what it implies for heterogeneity when combined with the sampling variance
(Note that because we have multilevel models, we need to account for that when doing prior checks to chose the SD, hence the two "lvl"s of variation sampled below)

```{r prior-check-1}
set.seed(42)

test <- tibble(
  var_res = mean(vres_tab$var_res),
  priorSD = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)
) |>
  group_by(priorSD) |>
  mutate(simulated_vars = map(.x = priorSD, .f = function(.x) {
    tibble(
      var_lvl1 = (abs(rnorm(10000, 0, priorSD)))^2,
      var_lvl2 = (abs(rnorm(10000, 0, priorSD)))^2
    )
  })) |>
  unnest(cols = simulated_vars) |>
  mutate(priorI2 = (var_lvl1 + var_lvl2) / (var_lvl1 + var_lvl2 + var_res))

p_prior_I2 <- ggplot(test) +
  geom_violin(aes(factor(priorSD), priorI2), fill = "#998ec3", col = "#998ec3", scale = "width") +
  geom_hline(yintercept = 0.8467, linetype = 1) + # median from senior et al 2016
  geom_hline(yintercept = 0.9169, linetype = 2) + # mean
  stat_summary(aes(factor(priorSD), priorI2),
    fun = "median", fun.min = "median", fun.max = "median",
    pch = 21, fill = "black", size = 0.7
  ) +
  stat_summary(aes(factor(priorSD), priorI2),
    fun = "mean", fun.min = "mean", fun.max = "mean",
    pch = 21, fill = "white", size = 0.7
  ) +
  scale_x_discrete("scale value for the random effect prior") +
  scale_y_continuous("resulting prior relative heterogeneity *I*^2^") +
  theme_bw() +
  theme(axis.title.y = element_markdown())

p_prior_I2
```

a $\mathrm{HalfNormal}(0,0.4)$ on random effects SDs would seem to behave well for both median and mean; priors much with smaller or larger scales tend to undershoot or overshoot expectations, respectively.

For the fixed effect priors, we follow the idea in Röver et al (https://doi.org/10.1002/jrsm.1475) that there is a link with the expected prior heterogeneity (so the total RE variance).

```{r prior-check-3}
p_prior_bwSD <- ggplot(test) +
  geom_violin(aes(factor(priorSD), sqrt(var_lvl1 + var_lvl2)), fill = "#998ec3", col = "#998ec3", scale = "width") +
  stat_summary(aes(factor(priorSD), sqrt(var_lvl1 + var_lvl2)),
    fun = "median", fun.min = "median", fun.max = "median",
    pch = 21, fill = "black", size = 0.7
  ) +
  stat_summary(aes(factor(priorSD), sqrt(var_lvl1 + var_lvl2)),
    fun = "mean", fun.min = "mean", fun.max = "mean",
    pch = 21, fill = "white", size = 0.7
  ) +
  scale_x_discrete("scale value for the random effect prior") +
  scale_y_continuous("resulting prior for the total between-studies SD") +
  theme_bw()

p_prior_bwSD
```

For `priorSD` = 0.4, this falls around 0.5.

Let's save these plots for supplementary material

```{r combine-prior-plots}
plot_prior <- (p_prior_I2 / p_prior_bwSD) + plot_layout(axis_titles = "collect")
plot_prior_horizontal <- (p_prior_I2 | p_prior_bwSD) + plot_layout(axis_titles = "collect")
```

```{r save-prior-plots, dev='cairo_pdf'}
ggsave(here("plots", "SUPPL_prior_I2.pdf"),
  plot = plot_prior, width = 4, height = 7
)

ggsave(here("plots", "SUPPL_prior_I2.png"),
  plot = plot_prior, width = 4, height = 7
)

ggsave(here("plots", "SUPPL_prior_I2_horizontal.pdf"),
  plot = plot_prior_horizontal, width = 8, height = 4
)

ggsave(here("plots", "SUPPL_prior_I2_horizontal.png"),
  plot = plot_prior_horizontal, width = 8, height = 4
)
```

We can now move to the models

### the models

```{r models-no-moderators}
fit_meta_int <- function(data, resp, adapt_delta = 0.99, iter = 4000, warmup = 2000) {
  # bayesian meta-analytic models are a bit harder to make converge than usual models, hence,the higher default adapt_delta
  model <- brm(
    yi | se(sqrt(vi)) ~ (1 | urban_area / study),
    data = data |> filter(response_name == resp),
    seed = 42,
    prior = c(
      set_prior("normal(0,0.5)", class = "Intercept"),
      set_prior("normal(0,0.4)", class = "sd")
      # the prior for SD set based on arguments in Röver 2021 on expected heterogenity
      # of z transformed correlations coefficients (both theoretical and compilation of observed tau)
      # note we have two levels between which total tau is spread, so we could even be narrower
    ),
    control = list(adapt_delta = adapt_delta),
    iter = iter, warmup = warmup
  )
  return(model)
}

modint_size <- fit_meta_int(data, "spider_length")
modint_abdomen <- fit_meta_int(data, "log_abdomen")
modint_brightness <- fit_meta_int(data, "brightness")
modint_radius <- fit_meta_int(data, "radius")
modint_mesh <- fit_meta_int(data, "mesh_size")
```

```{r summary-model}
summary(modint_size)
## look at Rhat and ESSs
pp_check(modint_size)
pp_check(modint_size, "pit_ecdf")
## see help to see what other posterior predictive checks may be useful
```


### get model quantities


```{r prep-plot-annotations}
plot_annotations <- tibble(
  response_name = c(
    "log_abdomen", "spider_length", "radius", "mesh_size", "brightness"
  ),
  full_names = c(
    "relative abdomen area", "spider length",
    "web radius", "mesh width",
    "abdomen brightness"
  ),
  negative_annotation = c(
    "smaller \n in cities", "smaller \n in cities",
    "smaller webs \n in cities", "tighter meshes\n in cities",
    "darker \n in cities"
  ),
  positive_annotation = c(
    "larger \n in cities", "larger \n in cities",
    "larger webs \n in cities", "looser meshes\n in cities",
    "lighter \n in cities"
  )
)
```

```{r get-fits-functions}
## prediction for the individual effect sizes
get_ES_fits <- function(model, data, response) {
  data |>
    ungroup() |>
    filter(response_name == response) |>
    select(urban_area, year, study, response_name, yi, vi) |>
    add_epred_draws(model, re_formula = ~ (1 | urban_area / study)) |>
    ungroup() |>
    select(urban_area, year, study, .draw, .epred)
}

## posterior for the overall distribution of ES (for prediction interval)
get_PI_fits <- function(model) {
  tibble(yi = 0, vi = 0, urban_area = "x", year = "x", study = "x") |> ## all variables are placeholders here
    add_epred_draws(model, re_formula = ~ (1 | urban_area / study), allow_new_levels = TRUE) |>
    ungroup() |>
    select(overall.PI = .epred, .draw, .iteration, .chain)
}

## overal effect

get_overall_fits <- function(model) { # get the overall intercept (so meaningful only for intercept-only models)
  as_draws_df(model) |>
    as_tibble() |>
    select(overall.epred = b_Intercept, .draw, .iteration, .chain)
}
```

```{r get-ES-fits}
ES_fits <- tibble(
  ES_fits = list(
    get_ES_fits(modint_abdomen, data, "log_abdomen"),
    get_ES_fits(modint_size, data, "spider_length"),
    get_ES_fits(modint_radius, data, "radius"),
    get_ES_fits(modint_mesh, data, "mesh_size"),
    get_ES_fits(modint_brightness, data, "brightness")
  ),
  response_name = c(
    "log_abdomen", "spider_length", "radius", "mesh_size", "brightness"
  )
) |>
  left_join(plot_annotations) |>
  unnest(ES_fits)
```


```{r get-PI-fits}
PI_fits <- tibble(
  PI_fits = list(
    get_PI_fits(modint_abdomen),
    get_PI_fits(modint_size),
    get_PI_fits(modint_radius),
    get_PI_fits(modint_mesh),
    get_PI_fits(modint_brightness)
  ),
  response_name = c(
    "log_abdomen", "spider_length", "radius", "mesh_size", "brightness"
  )
) |>
  unnest(PI_fits)
```

```{r get-overall-fits}
overall_fits <- tibble(
  overall_fits = list(
    get_overall_fits(modint_abdomen),
    get_overall_fits(modint_size),
    get_overall_fits(modint_radius),
    get_overall_fits(modint_mesh),
    get_overall_fits(modint_brightness)
  ),
  response_name = c(
    "log_abdomen", "spider_length", "radius", "mesh_size", "brightness"
  )
) |>
  unnest(overall_fits) |>
  mutate(overall.r = metafor::transf.ztor(overall.epred))
```


```{r get-var-comps}
vres_tab <- data |>
  filter(!is.na(yi)) |>
  group_by(response_name) |>
  summarise(k = length(yi), sum_wi = sum(1 / vi), sum_wi_squared = sum((1 / (vi))^2)) |>
  mutate(var_res = (k - 1) * sum_wi / (sum_wi^2 - sum_wi_squared))
## see https://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate?s[]=heterogeneity
# and Nakagawa et al 2023 paper

get_varcomps <- function(model) {
  as_draws_df(model) |>
    select(starts_with("sd"), .draw, .iteration, .chain) |>
    pivot_longer(cols = -c(.draw, .iteration, .chain)) |>
    mutate(var_level = str_split_fixed(name, "__", 2)[, 1]) |>
    mutate(var_level = str_remove(var_level, "sd_")) |>
    mutate(var_level = case_when(var_level == "urban_area" ~ "SD_urban_area", TRUE ~ "SD_study")) |>
    select(-name) |>
    pivot_wider(names_from = var_level, values_from = value)
}

varcomps <- tibble(
  varcomps = list(
    get_varcomps(modint_abdomen),
    get_varcomps(modint_size),
    get_varcomps(modint_mesh),
    get_varcomps(modint_radius),
    get_varcomps(modint_brightness)
  ),
  response_name = c(
    "log_abdomen", "spider_length", "radius", "mesh_size", "brightness"
  )
) |>
  unnest(varcomps) |>
  left_join(vres_tab)

varcomps <- varcomps |>
  mutate(var_rand = SD_urban_area^2 + SD_study^2) |>
  mutate(
    I2 = var_rand / (var_rand + var_res),
    p_between = SD_urban_area^2 / var_rand
  )
```

### Table 1

### Table


```{r table1}
tab_overall <- left_join(overall_fits, varcomps) |>
  group_by(response_name) |>
  mean_qi(overall.epred, I2, var_rand, p_between) |>
  left_join(plot_annotations) |>
  mutate(nonzero = sign(overall.epred.lower) == sign(overall.epred.upper)) |>
  select(
    full_names,
    overall.epred, overall.epred.lower, overall.epred.upper, nonzero,
    I2, I2.lower, I2.upper,
    var_rand, var_rand.lower, var_rand.upper,
    p_between, p_between.lower, p_between.upper
  )


table1 <- tab_overall |>
  mutate(print_ES = paste0(
    sprintf("%.2f", round(overall.epred, 2)),
    " \\[",
    sprintf("%.2f", round(overall.epred.lower, 2)),
    ", ",
    sprintf("%.2f", round(overall.epred.upper, 2)),
    "\\]"
  )) |>
  mutate(print_tau2 = paste0(
    sprintf("%.2f", round(var_rand, 2)),
    " \\[",
    sprintf("%.2f", round(var_rand.lower, 2)),
    ", ",
    sprintf("%.2f", round(var_rand.upper, 2)),
    "\\]"
  )) |>
  mutate(print_I2 = paste0(
    sprintf("%.2f", round(I2, 2)),
    " \\[",
    sprintf("%.2f", round(I2.lower, 2)),
    ", ",
    sprintf("%.2f", round(I2.upper, 2)),
    "\\]"
  )) |>
  mutate(print_p = paste0(
    sprintf("%.2f", round(p_between, 2)),
    " \\[",
    sprintf("%.2f", round(p_between.lower, 2)),
    ", ",
    sprintf("%.2f", round(p_between.upper, 2)),
    "\\]"
  )) |>
  mutate(print_ES = case_when(nonzero ~ paste0("**", print_ES, "**"), TRUE ~ print_ES)) |>
  select(
    trait = full_names,
    `predicted overall mean _Zr_` = print_ES,
    `absolute heterogeneity $\\tau^2 + \\sigma^2$` = print_tau2,
    `relative heterogeneity _I^2^_` = print_I2,
    `proportion of absolute heterogeneity associated with between-cities differences` = print_p
  ) |>
  mutate(trait = fct_relevel(
    trait,
    "spider length", "relative abdomen area",
    "mesh width", "web radius",
    "abdomen brightness"
  )) |>
  arrange(trait)

# knitr::kable(table1)
knitr::kable(table1 |> # pivot the table
  pivot_longer(cols = -trait) |>
  rename(`  ` = "name") |>
  pivot_wider(names_from = trait, values_from = value))
```

### Plots

```{r plot-colours}
main_colour <- "#998ec3"
pale_colour <- "#d8daeb"
```

#### caterpillar plots

```{r caterpillar-plot-function}
make_caterpillar_plot <- function(ES_fits, PI_fits, overall_fits, ES_observed, plot_annotations, response) {
  filtered_observed <- ES_observed |> filter(response_name == response)
  filtered_PI <- PI_fits |> filter(response_name == response)
  filtered_ES <- ES_fits |> filter(response_name == response)
  filtered_overall <- overall_fits |> filter(response_name == response)
  ranking <- ES_fits |>
    filter(response_name == response) |>
    group_by(study) |>
    summarise(mean = mean(.epred)) |>
    mutate(ranked = factor(rank(mean)))

  p_main <- ggplot() +
    stat_lineribbon(
      data = expand_grid(filtered_PI, ranking),
      aes(x = overall.PI, y = ranked), .width = 0.95, fill = pale_colour
    ) +
    stat_lineribbon(
      data = expand_grid(filtered_overall, ranking),
      aes(x = overall.epred, y = ranked), .width = 0.95, fill = main_colour
    ) +
    stat_pointinterval(
      data = filtered_ES |> left_join(ranking),
      aes(x = .epred, y = ranked), .width = c(0, 0.95),
    ) +
    geom_point(
      data = filtered_observed |> left_join(ranking),
      aes(x = yi, y = ranked, size = 1 / vi),
      pch = 21, fill = "white", alpha = 0.5
    ) +
    geom_vline(xintercept = 0, linetype = 2) +
    scale_y_discrete("", limits = rev) +
    scale_x_continuous("effect size (Zr)") +
    coord_cartesian(xlim = c(-1.2, 1.2)) +
    facet_wrap(~full_names) +
    theme_bw() +
    theme(
      legend.position = "none",
      axis.ticks.y = element_blank(),
      axis.text.y = element_blank()
    )


  p_main
}
```

```{r caterpillar-plots}
plot_abdomen <- make_caterpillar_plot(ES_fits, PI_fits, overall_fits, data, plot_annotations, "log_abdomen")
plot_size <- make_caterpillar_plot(ES_fits, PI_fits, overall_fits, data, plot_annotations, "spider_length")
plot_radius <- make_caterpillar_plot(ES_fits, PI_fits, overall_fits, data, plot_annotations, "radius")
plot_mesh <- make_caterpillar_plot(ES_fits, PI_fits, overall_fits, data, plot_annotations, "mesh_size")
plot_brightness <- make_caterpillar_plot(ES_fits, PI_fits, overall_fits, data, plot_annotations, "brightness")


caterplot <- (plot_size + plot_abdomen + plot_radius + plot_mesh + plot_brightness) +
  plot_layout(ncol = 3, nrow = 2)
```

```{r save-caterpillar-plots, dev='cairo_pdf'}
ggsave(here("plots", "fig4.pdf"), plot = caterplot, width = 9, height = 6)
ggsave(here("plots", "fig4.png"), plot = caterplot, width = 9, height = 6)
```



### SUPPLEMENTARY FIGURES


#### "forest" plots

The first version, used in first drafts

```{r make-forest-plot-function}
make_forest_plot <- function(ES_fits, PI_fits, overall_fits, ES_observed, plot_annotations, response) {
  study_list <- filter(ES_observed, response_name == response)$study

  p_main <- ggplot() +
    stat_lineribbon(
      data = expand_grid(PI_fits |> filter(response_name == response), study = study_list),
      aes(x = overall.PI, y = study), .width = 0.95, fill = pale_colour
    ) +
    stat_lineribbon(
      data = expand_grid(overall_fits |> filter(response_name == response), study = study_list),
      aes(x = overall.epred, y = study), .width = 0.95, fill = main_colour
    ) +
    stat_pointinterval(
      data = ES_fits |> filter(response_name == response),
      aes(x = .epred, y = study), .width = c(0, 0.95),
    ) +
    geom_point(
      data = left_join(ES_observed, plot_annotations) |> filter(response_name == response),
      aes(x = yi, y = study, size = 1 / vi),
      pch = 21, fill = "white", alpha = 0.5
    ) +
    geom_vline(xintercept = 0, linetype = 2) +
    scale_y_discrete("City and Year of visit", limits = rev) +
    scale_x_continuous("effect size (Zr)") +
    coord_cartesian(xlim = c(-1.2, 1.2)) +
    facet_wrap(~full_names) +
    theme_bw() +
    theme(legend.position = "none")


  arrows_annotate <- plot_annotations |>
    filter(response_name == response) |>
    pivot_longer(
      cols = c(negative_annotation, positive_annotation),
      values_to = "label"
    ) |>
    mutate(x = c(-0.4, 0.4)) |>
    ggplot() +
    geom_segment(aes(x = x * 0.25, xend = x * 0.8, y = 0, yend = 0),
      arrow = arrow(type = "closed", angle = 15, length = unit(0.5, "cm"))
    ) +
    geom_text(aes(x = 0.9 * x, y = 0, label = label, hjust = c(1, 0))) +
    coord_cartesian(xlim = c(-0.8, 0.8)) +
    theme_void()

  (p_main / arrows_annotate) + plot_layout(heights = c(0.85, 0.15))
}
```

A second version, that groups and reorders effect sizes by countries. The first version above is kept as a useful check to make sure we have a way to double check everything is reordered correctly

```{r make-forest-plot-function2}
make_forest_plot2 <- function(ES_fits, PI_fits, overall_fits, ES_observed, plot_annotations, response) {
  study_list <- filter(ES_observed, response_name == response) |>
    ungroup() |>
    select(country, study)
  reordered_studies <- function(study_list) {
    arrange(study_list, country, study)
  }

  key <- reordered_studies(study_list) |>
    mutate(studyY = 1:length(study)) |>
    group_by(country) |>
    summarize(start = min(studyY), end = max(studyY))

  key <- key_range_manual(
    start = (max(key$end) + 1.25) - key$start, end = (max(key$end) + 0.75) - key$end, name = key$country
  )

  p_main <- ggplot() +
    stat_lineribbon(
      data = expand_grid(PI_fits |> filter(response_name == response), 
                         study_list|> 
                           mutate(study = fct_relevel(
                             study,
                             reordered_studies(study_list)$study))
                         )
      ,
      aes(x = overall.PI, y = study), .width = 0.95, fill = pale_colour
    ) +
    stat_lineribbon(
      data = expand_grid(overall_fits |> filter(response_name == response), 
                         study_list|> 
                           mutate(study = fct_relevel(
                             study,
                             reordered_studies(study_list)$study))),
      aes(x = overall.epred, y = study), .width = 0.95, fill = main_colour
    ) +
    stat_pointinterval(
      data = ES_fits |> filter(response_name == response),
      aes(x = .epred, y = study), .width = c(0, 0.95),
    ) +
    geom_point(
      data = left_join(ES_observed, plot_annotations) |> filter(response_name == response),
      aes(x = yi, y = study, size = 1 / vi),
      pch = 21, fill = "white", alpha = 0.5
    ) +
    geom_vline(xintercept = 0, linetype = 2) +
    scale_y_discrete("", limits = rev) +
    scale_x_continuous("effect size (Zr)") +
    coord_cartesian(xlim = c(-1.2, 1.2)) +
    facet_wrap(~full_names) +
    guides(
      y = compose_stack(
        primitive_ticks(),
        primitive_labels(),
        primitive_bracket(key = key)
      )
    ) +
    theme_bw() +
    theme(legend.position = "none")


  arrows_annotate <- plot_annotations |>
    filter(response_name == response) |>
    pivot_longer(
      cols = c(negative_annotation, positive_annotation),
      values_to = "label"
    ) |>
    mutate(x = c(-0.4, 0.4)) |>
    ggplot() +
    geom_segment(aes(x = x * 0.25, xend = x * 0.8, y = 0, yend = 0),
      arrow = arrow(type = "closed", angle = 15, length = unit(0.5, "cm"))
    ) +
    geom_text(aes(x = 0.9 * x, y = 0, label = label, hjust = c(1, 0))) +
    coord_cartesian(xlim = c(-0.8, 0.8)) +
    theme_void()

  (p_main / arrows_annotate) + plot_layout(heights = c(0.85, 0.15))
}
```

```{r make-forest-plots}
plot_abdomen <- make_forest_plot2(ES_fits, PI_fits, overall_fits, data, plot_annotations, "log_abdomen")
plot_size <- make_forest_plot2(ES_fits, PI_fits, overall_fits, data, plot_annotations, "spider_length")
plot_radius <- make_forest_plot2(ES_fits, PI_fits, overall_fits, data, plot_annotations, "radius")
plot_mesh <- make_forest_plot2(ES_fits, PI_fits, overall_fits, data, plot_annotations, "mesh_size")
plot_brightness <- make_forest_plot2(ES_fits, PI_fits, overall_fits, data, plot_annotations, "brightness")
```

```{r save-forest-plots, dev='cairo_pdf'}
ggsave(here("plots", "SUPPL_forest_abdomen.pdf"), plot = plot_abdomen, width = 6, height = 6)
ggsave(here("plots", "SUPPL_forest_abdomen.png"), plot = plot_abdomen, width = 6, height = 6)

ggsave(here("plots", "SUPPL_forest_size.pdf"), plot = plot_size, width = 6, height = 6)
ggsave(here("plots", "SUPPL_forest_size.png"), plot = plot_size, width = 6, height = 6)

ggsave(here("plots", "SUPPL_forest_radius.pdf"), plot = plot_radius, width = 6, height = 6)
ggsave(here("plots", "SUPPL_forest_radius.png"), plot = plot_radius, width = 6, height = 6)

ggsave(here("plots", "SUPPL_forest_mesh.pdf"), plot = plot_mesh, width = 6, height = 6)
ggsave(here("plots", "SUPPL_forest_mesh.png"), plot = plot_mesh, width = 6, height = 6)

ggsave(here("plots", "SUPPL_forest_brightness.pdf"), plot = plot_brightness, width = 6, height = 6)
ggsave(here("plots", "SUPPL_forest_brightness.png"), plot = plot_brightness, width = 6, height = 6)
```


#### heterogeneity plots


```{r heterogeneity-plots}
plot_I2 <- ggplot(varcomps |> left_join(plot_annotations)) +
  stat_halfeye(aes(x = I2, y = full_names),
    .width = c(0, 0.95), fill = main_colour, point_interval = "mean_qi"
  ) +
  scale_x_continuous("relative heterogeneity *I*^2^", limits = c(0, 1)) +
  scale_y_discrete("", limits = rev) +
  theme_bw() +
  theme(axis.title.x = element_markdown())

plot_abs_heterogeneity <- ggplot(varcomps |> left_join(plot_annotations)) +
  stat_halfeye(aes(x = var_rand, y = full_names),
    .width = c(0, 0.95), fill = main_colour, point_interval = "mean_qi"
  ) +
  scale_x_continuous("absolute heterogeneity \U03C4^2^ + \U03C3^2^") +
  scale_y_discrete("", limits = rev) +
  theme_bw() +
  theme(axis.title.x = element_markdown())

plot_between_within <- ggplot(varcomps |> left_join(plot_annotations)) +
  stat_halfeye(aes(x = p_between, y = full_names),
    .width = c(0, 0.95), fill = main_colour, point_interval = "mean_qi"
  ) +
  scale_x_continuous("city-level repeatability", limits = c(0, 1)) +
  scale_y_discrete("", limits = rev) +
  theme_bw() +
  theme(axis.title.x = element_markdown())
```


```{r save-heterogeneity-plots, dev='cairo_pdf'}
ggsave(here("plots", "SUPPL_I2.pdf"),
  plot = plot_I2, width = 5, height = 5, device = cairo_pdf
)
ggsave(here("plots", "SUPPL_I2.png"),
  plot = plot_I2, width = 5, height = 5
)

ggsave(here("plots", "SUPPL_abs_heterogeneity.pdf"),
  plot = plot_abs_heterogeneity, width = 5, height = 5, device = cairo_pdf
)
ggsave(here("plots", "SUPPL_abs_heterogeneity.png"),
  plot = plot_abs_heterogeneity, width = 5, height = 5
)

ggsave(here("plots", "SUPPL_between_within.pdf"),
  plot = plot_between_within, width = 5, height = 5, device = cairo_pdf
)
ggsave(here("plots", "SUPPL_between_within.png"),
  plot = plot_between_within, width = 5, height = 5
)
```
